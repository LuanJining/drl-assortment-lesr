import json
import numpy as np
import re
import time
import logging
import requests
from typing import Dict, List, Tuple, Optional

# å°è¯•å¯¼å…¥OpenAIï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨requestsä½œä¸ºå¤‡é€‰
try:
    from openai import OpenAI

    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("Warning: OpenAIåº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨requestsåº“")


class LLMOptimizer:
    def __init__(self, api_key: str, base_url: str, model: str = "gpt-4o-mini"):
        self.api_key = api_key
        self.base_url = base_url.rstrip('/')  # ç§»é™¤æœ«å°¾çš„æ–œæ 
        self.model = model
        self.iteration_history = []
        self.best_functions = {}

        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.client = None
        self.use_requests = False
        self._init_client()

    def _init_client(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        # é¦–å…ˆå°è¯•ä½¿ç”¨requestsåº“ï¼ˆå› ä¸ºæµ‹è¯•æ˜¾ç¤ºå®ƒèƒ½æ­£å¸¸å·¥ä½œï¼‰
        if self._test_requests_connection():
            self.logger.info("ä½¿ç”¨requestsåº“è¿›è¡ŒAPIè°ƒç”¨")
            self.use_requests = True
            return True

        # å¦‚æœrequestså¤±è´¥ï¼Œå°è¯•OpenAIå®¢æˆ·ç«¯
        if OPENAI_AVAILABLE:
            try:
                # ç®€åŒ–çš„OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–ï¼Œåªä½¿ç”¨å¿…è¦å‚æ•°
                self.client = OpenAI(
                    api_key=self.api_key,
                    base_url=self.base_url
                )

                # æµ‹è¯•è¿æ¥
                if self._test_openai_connection():
                    self.logger.info("ä½¿ç”¨OpenAIå®¢æˆ·ç«¯è¿›è¡ŒAPIè°ƒç”¨")
                    return True
                else:
                    self.client = None

            except Exception as e:
                self.logger.error(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                self.client = None

        # å¦‚æœéƒ½å¤±è´¥ï¼Œè®°å½•è­¦å‘Š
        self.logger.warning("æ‰€æœ‰APIè¿æ¥æ–¹å¼éƒ½å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤å‡½æ•°")
        return False

    def _test_requests_connection(self):
        """æµ‹è¯•requestsè¿æ¥"""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            data = {
                "model": self.model,
                "messages": [{"role": "user", "content": "test"}],
                "max_tokens": 5
            }

            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=data,
                timeout=10
            )

            return response.status_code == 200

        except Exception as e:
            self.logger.error(f"Requestsè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False

    def _test_openai_connection(self):
        """æµ‹è¯•OpenAIå®¢æˆ·ç«¯è¿æ¥"""
        try:
            if self.client is None:
                return False

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "test"}],
                max_tokens=5
            )

            return True

        except Exception as e:
            self.logger.error(f"OpenAIå®¢æˆ·ç«¯è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False

    def _make_request_with_requests(self, messages: List[Dict], max_retries: int = 3):
        """ä½¿ç”¨requestsåº“è¿›è¡ŒAPIè°ƒç”¨"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": self.model,
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 2000
        }

        for attempt in range(max_retries):
            try:
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=data,
                    timeout=30
                )

                if response.status_code == 200:
                    result = response.json()
                    content = result['choices'][0]['message']['content']
                    if content:
                        return content
                    else:
                        raise ValueError("APIè¿”å›ç©ºå†…å®¹")
                else:
                    raise Exception(f"APIè¿”å›é”™è¯¯çŠ¶æ€ç : {response.status_code}, å†…å®¹: {response.text}")

            except Exception as e:
                self.logger.warning(f"Requests APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")

                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2
                    self.logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    raise

    def _make_request_with_openai(self, messages: List[Dict], max_retries: int = 3):
        """ä½¿ç”¨OpenAIå®¢æˆ·ç«¯è¿›è¡ŒAPIè°ƒç”¨"""
        if self.client is None:
            raise Exception("OpenAIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")

        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=2000
                )

                content = response.choices[0].message.content
                if content:
                    return content
                else:
                    raise ValueError("APIè¿”å›ç©ºå†…å®¹")

            except Exception as e:
                self.logger.warning(f"OpenAI APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")

                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2
                    self.logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    raise

    def _make_request(self, messages: List[Dict]):
        """æ™ºèƒ½é€‰æ‹©APIè°ƒç”¨æ–¹å¼"""
        if self.use_requests:
            return self._make_request_with_requests(messages)
        elif self.client is not None:
            return self._make_request_with_openai(messages)
        else:
            raise Exception("æ²¡æœ‰å¯ç”¨çš„APIè¿æ¥æ–¹å¼")

    def _clean_generated_code(self, code: str) -> str:
        """ğŸ”§ æ–°å¢ï¼šæ¸…ç†ç”Ÿæˆçš„ä»£ç ï¼Œä¿®å¤å¸¸è§é—®é¢˜"""
        if not code:
            return code

        import re

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç²¾ç¡®æ›¿æ¢ï¼Œé¿å…é‡å¤æ›¿æ¢
        # åªæ›¿æ¢ np.float ä½†ä¸æ›¿æ¢ np.float32/np.float64 ç­‰
        code = re.sub(r'\bnp\.float\b(?!32|64|16)', 'np.float64', code)
        code = re.sub(r'\bnp\.int\b(?!8|16|32|64)', 'np.int64', code)
        code = re.sub(r'\bnp\.bool\b(?!_)', 'np.bool_', code)

        # åŒæ ·å¤„ç† numpy.xxx æ ¼å¼
        code = re.sub(r'\bnumpy\.float\b(?!32|64|16)', 'numpy.float64', code)
        code = re.sub(r'\bnumpy\.int\b(?!8|16|32|64)', 'numpy.int64', code)
        code = re.sub(r'\bnumpy\.bool\b(?!_)', 'numpy.bool_', code)

        # ç¡®ä¿æœ‰numpyå¯¼å…¥
        if 'import numpy' not in code and 'import np' not in code:
            code = 'import numpy as np\n\n' + code

        return code

    def generate_state_representation(self,
                                      task_description: str,
                                      state_info: Dict) -> str:
        """ç”ŸæˆçŠ¶æ€è¡¨ç¤ºå‡½æ•°"""
        # å¦‚æœæ²¡æœ‰å¯ç”¨çš„APIè¿æ¥ï¼Œç›´æ¥è¿”å›é»˜è®¤å‡½æ•°
        if not self.use_requests and self.client is None:
            self.logger.warning("APIä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤çŠ¶æ€å‡½æ•°")
            return self._get_default_state_function()

        prompt = self._create_state_prompt(task_description, state_info)
        messages = [{"role": "user", "content": prompt}]

        try:
            content = self._make_request(messages)
            code = self._extract_code(content)

            if code:
                # ğŸ”§ æ·»åŠ ä»£ç æ¸…ç†æ­¥éª¤
                code = self._clean_generated_code(code)
                self.logger.info("æˆåŠŸç”ŸæˆçŠ¶æ€è¡¨ç¤ºå‡½æ•°")
                return code
            else:
                self.logger.warning("æœªèƒ½ä»å“åº”ä¸­æå–ä»£ç ï¼Œä½¿ç”¨é»˜è®¤å‡½æ•°")
                return self._get_default_state_function()

        except Exception as e:
            self.logger.error(f"ç”ŸæˆçŠ¶æ€è¡¨ç¤ºå‡½æ•°å¤±è´¥: {e}")
            self.logger.info("ä½¿ç”¨é»˜è®¤çŠ¶æ€è¡¨ç¤ºå‡½æ•°")
            return self._get_default_state_function()

    def generate_intrinsic_reward(self,
                                  state_representation: str,
                                  performance_feedback: Dict = None) -> str:
        """ç”Ÿæˆå†…åœ¨å¥–åŠ±å‡½æ•°"""
        # å¦‚æœæ²¡æœ‰å¯ç”¨çš„APIè¿æ¥ï¼Œç›´æ¥è¿”å›é»˜è®¤å‡½æ•°
        if not self.use_requests and self.client is None:
            self.logger.warning("APIä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤å¥–åŠ±å‡½æ•°")
            return self._get_default_reward_function()

        prompt = self._create_reward_prompt(state_representation, performance_feedback)
        messages = [{"role": "user", "content": prompt}]

        try:
            content = self._make_request(messages)
            code = self._extract_code(content)

            if code:
                # ğŸ”§ æ·»åŠ ä»£ç æ¸…ç†æ­¥éª¤
                code = self._clean_generated_code(code)
                self.logger.info("æˆåŠŸç”Ÿæˆå†…åœ¨å¥–åŠ±å‡½æ•°")
                return code
            else:
                self.logger.warning("æœªèƒ½ä»å“åº”ä¸­æå–ä»£ç ï¼Œä½¿ç”¨é»˜è®¤å‡½æ•°")
                return self._get_default_reward_function()

        except Exception as e:
            self.logger.error(f"ç”Ÿæˆå†…åœ¨å¥–åŠ±å‡½æ•°å¤±è´¥: {e}")
            self.logger.info("ä½¿ç”¨é»˜è®¤å¥–åŠ±å‡½æ•°")
            return self._get_default_reward_function()

    def update_with_feedback(self, feedback: Dict):
        """åŸºäºåé¦ˆæ›´æ–°ä¼˜åŒ–ç­–ç•¥"""
        self.iteration_history.append(feedback)

    def _extract_code(self, response_text: str) -> str:
        """ä»LLMå“åº”ä¸­æå–Pythonä»£ç """
        if not response_text:
            return ""

        # æŸ¥æ‰¾ä»£ç å—
        code_pattern = r'```python\n(.*?)```'
        matches = re.findall(code_pattern, response_text, re.DOTALL)

        if matches:
            return matches[0].strip()

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡è®°çš„ä»£ç å—ï¼Œå°è¯•æå–å‡½æ•°å®šä¹‰
        func_pattern = r'(def\s+\w+\s*\([^)]*\):.*?)(?=\n\n|\n(?:def|class|import|#)|$)'
        func_matches = re.findall(func_pattern, response_text, re.DOTALL)

        if func_matches:
            return '\n\n'.join(func_matches).strip()

        return response_text.strip()

    def _get_default_state_function(self) -> str:
        """è·å–é»˜è®¤çŠ¶æ€å¢å¼ºå‡½æ•°"""
        return """
import numpy as np

def enhance_state(inventory, customer_type, prices, time_remaining, initial_inventory):
    base_state = []

    # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
    inventory = np.array(inventory, dtype=np.float32)
    initial_inventory = np.array(initial_inventory, dtype=np.float32)
    prices = np.array(prices, dtype=np.float32) if prices is not None else np.ones(len(inventory), dtype=np.float32)

    # ç›¸å¯¹åº“å­˜
    relative_inventory = inventory / (initial_inventory + 1e-8)
    base_state.extend(relative_inventory.tolist())

    # å®¢æˆ·ç±»å‹one-hotç¼–ç 
    customer_encoding = np.zeros(4, dtype=np.float32)
    if 0 <= customer_type < 4:
        customer_encoding[int(customer_type)] = 1.0
    base_state.extend(customer_encoding.tolist())

    # æ—¶é—´ç‰¹å¾
    base_state.append(float(time_remaining) / 100.0)

    # å¢å¼ºç‰¹å¾
    inventory_sum = float(inventory.sum())
    initial_sum = float(initial_inventory.sum())

    # åº“å­˜å‹åŠ›
    pressure = 1.0 - (inventory_sum / (initial_sum + 1e-8))
    base_state.append(pressure)

    # åº“å­˜ä¸å¹³è¡¡åº¦
    imbalance = float(np.std(relative_inventory))
    base_state.append(imbalance)

    # ä½åº“å­˜äº§å“æ¯”ä¾‹
    low_stock_ratio = float(np.mean(relative_inventory < 0.3))
    base_state.append(low_stock_ratio)

    # ä»·æ ¼åŠ æƒåº“å­˜
    if len(prices) == len(inventory):
        weighted_inventory = float(np.sum(prices * inventory)) / (float(np.sum(prices * initial_inventory)) + 1e-8)
    else:
        weighted_inventory = 0.5
    base_state.append(weighted_inventory)

    return np.array(base_state, dtype=np.float32)
        """.strip()

    def _get_default_reward_function(self) -> str:
        """è·å–é»˜è®¤å¥–åŠ±å‡½æ•°"""
        return """
import numpy as np

def intrinsic_reward(state, action, next_state, sold_item, price):
    reward = 0.0

    try:
        # é”€å”®å¥–åŠ±
        if sold_item >= 0 and price > 0:
            reward += float(price) * 0.1

        # åº“å­˜å¹³è¡¡å¥–åŠ±
        if len(state) > 10:
            inventory_features = state[:10]
            inventory_std = float(np.std(inventory_features))
            reward -= inventory_std * 0.05

        # æ—¶é—´å‹åŠ›å¥–åŠ±
        if len(state) > 14:
            time_remaining = float(state[14])
            reward += (1.0 - time_remaining) * 0.02

        # ç¡®ä¿å¥–åŠ±åœ¨åˆç†èŒƒå›´å†…
        reward = np.clip(reward, -10.0, 10.0)

    except Exception as e:
        # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œè¿”å›å°çš„æ­£å¥–åŠ±
        reward = 0.01

    return float(reward)
        """.strip()

    def _create_state_prompt(self, task_description: str, state_info: Dict) -> str:
        """åˆ›å»ºçŠ¶æ€è¡¨ç¤ºç”Ÿæˆæç¤º"""
        prompt = f"""
ä»»åŠ¡æè¿°ï¼š{task_description}

å½“å‰çŠ¶æ€ä¿¡æ¯ï¼š
- åº“å­˜æ°´å¹³ï¼š{state_info['inventory_shape']}ç»´å‘é‡ï¼Œè¡¨ç¤ºæ¯ä¸ªäº§å“çš„å‰©ä½™æ•°é‡
- å®¢æˆ·ç±»å‹ï¼š{state_info['customer_types']}ç§ä¸åŒç±»å‹çš„å®¢æˆ·
- äº§å“æ•°é‡ï¼š{state_info['num_products']}ä¸ªä¸åŒäº§å“
- å±•ç¤ºé™åˆ¶ï¼šæ¯æ¬¡æœ€å¤šå±•ç¤º{state_info.get('cardinality', 4)}ä¸ªäº§å“

è¯·è®¾è®¡ä¸€ä¸ªPythonå‡½æ•°æ¥å¢å¼ºçŠ¶æ€è¡¨ç¤ºã€‚å‡½æ•°åº”è¯¥ï¼š
1. è®¡ç®—åº“å­˜å‹åŠ›æŒ‡æ ‡ï¼ˆå¦‚ç›¸å¯¹åº“å­˜æ°´å¹³ã€åº“å­˜ä¸å¹³è¡¡åº¦ï¼‰
2. è¯„ä¼°åº“å­˜çš„ç´§æ€¥ç¨‹åº¦
3. è®¡ç®—é¢„æœŸçš„æœªæ¥ä»·å€¼
4. è¯„ä¼°åº“å­˜åˆ†å¸ƒçš„å‡è¡¡æ€§

âš ï¸ é‡è¦çº¦æŸï¼š
- å‡½æ•°åå¿…é¡»æ˜¯ enhance_state
- è¾“å…¥å‚æ•°: inventory, customer_type, prices, time_remaining, initial_inventory
- è¿”å› numpy.ndarray
- ä¸è¦ä½¿ç”¨ np.floatï¼Œä½¿ç”¨ float æˆ– np.float64
- ä¸è¦ä½¿ç”¨ np.intï¼Œä½¿ç”¨ int æˆ– np.int64
- å¯ä»¥ä½¿ç”¨ Python å†…ç½®å‡½æ•°ï¼šsum(), max(), min(), abs(), len(), float(), int() ç­‰
- å¤„ç†è¾¹ç•Œæƒ…å†µï¼Œé¿å…é™¤é›¶é”™è¯¯
- ç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½æ˜¯æœ‰æ„ä¹‰çš„æ•°å€¼

è¯·ç”Ÿæˆä¸€ä¸ªåˆ›æ–°çš„çŠ¶æ€å¢å¼ºå‡½æ•°ã€‚
"""
        return prompt

    def _create_reward_prompt(self, state_representation: str, performance_feedback: Dict) -> str:
        """åˆ›å»ºå¥–åŠ±å‡½æ•°ç”Ÿæˆæç¤º"""
        feedback_str = ""
        if performance_feedback:
            feedback_str = f"\næ€§èƒ½åé¦ˆï¼š{json.dumps(performance_feedback, indent=2, ensure_ascii=False)}"

        prompt = f"""
åŸºäºä»¥ä¸‹çŠ¶æ€è¡¨ç¤ºå‡½æ•°ï¼Œè®¾è®¡ä¸€ä¸ªå†…åœ¨å¥–åŠ±å‡½æ•°ï¼š

{state_representation}
{feedback_str}

è¯·è®¾è®¡ä¸€ä¸ªå†…åœ¨å¥–åŠ±å‡½æ•°ï¼Œå®ƒåº”è¯¥ï¼š
1. é¼“åŠ±åº“å­˜å¹³è¡¡
2. é¿å…ç¼ºè´§æƒ…å†µ
3. å¥–åŠ±é«˜ä»·å€¼äº§å“çš„é”€å”®
4. è€ƒè™‘æ—¶é—´å‹åŠ›å› ç´ 
5. æä¾›ç¨³å®šçš„å­¦ä¹ ä¿¡å·

âš ï¸ é‡è¦çº¦æŸï¼š
- å‡½æ•°åå¿…é¡»æ˜¯ intrinsic_reward
- è¾“å…¥å‚æ•°: state, action, next_state, sold_item, price
- è¿”å› float æ•°å€¼ï¼ˆæ ‡é‡ï¼‰
- ä¸è¦ä½¿ç”¨ np.floatï¼Œä½¿ç”¨ float æˆ– np.float64
- ä¸è¦ä½¿ç”¨ np.intï¼Œä½¿ç”¨ int æˆ– np.int64
- å¯ä»¥ä½¿ç”¨ Python å†…ç½®å‡½æ•°ï¼šsum(), max(), min(), abs(), len(), float(), int() ç­‰
- å¯ä»¥ä½¿ç”¨ numpy å‡½æ•°ï¼šnp.sum(), np.mean(), np.std(), np.sqrt() ç­‰
- æ•°å€¼ç¨³å®šï¼Œé¿å…å¼‚å¸¸æƒ…å†µ
- æä¾›æœ‰æ„ä¹‰çš„å­¦ä¹ ä¿¡å·

è¯·ç”Ÿæˆä¸€ä¸ªå¹³è¡¡ä¸”æœ‰æ•ˆçš„å†…åœ¨å¥–åŠ±å‡½æ•°ã€‚
"""
        return prompt

    def is_api_available(self):
        """æ£€æŸ¥APIæ˜¯å¦å¯ç”¨"""
        return self.use_requests or self.client is not None

    def get_connection_status(self):
        """è·å–è¿æ¥çŠ¶æ€ä¿¡æ¯"""
        if self.use_requests:
            return "ä½¿ç”¨requestsåº“è¿æ¥"
        elif self.client is not None:
            return "ä½¿ç”¨OpenAIå®¢æˆ·ç«¯è¿æ¥"
        else:
            return "æ— å¯ç”¨è¿æ¥ï¼Œä½¿ç”¨é»˜è®¤å‡½æ•°"