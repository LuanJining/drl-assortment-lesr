# DRL-Assortment-LESR

![Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)
![OpenAI](https://img.shields.io/badge/OpenAI-API-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

> **D**eep **R**einforcement **L**earning for **Assortment** optimization with **L**LM-**E**nhanced **S**tate **R**epresentation

ä¸€ä¸ªåˆ›æ–°çš„å¼ºåŒ–å­¦ä¹ é¡¹ç›®ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡å‹(LLM)è‡ªåŠ¨ç”ŸæˆçŠ¶æ€è¡¨ç¤ºå’Œå¥–åŠ±å‡½æ•°ï¼Œç”¨äºä¼˜åŒ–åœ¨çº¿å•†å“æ¨èç­–ç•¥ã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

DRL-Assortment-LESR æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿï¼Œä¸“é—¨è§£å†³ç”µå•†åœºæ™¯ä¸­çš„å•†å“æ¨èä¼˜åŒ–é—®é¢˜ã€‚é¡¹ç›®çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆå’Œä¼˜åŒ–çŠ¶æ€è¡¨ç¤ºå‡½æ•°ä¸å†…åœ¨å¥–åŠ±å‡½æ•°ï¼Œä»è€Œæå‡å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„æ€§èƒ½ã€‚

### âœ¨ ä¸»è¦ç‰¹æ€§

- ğŸ¤– **LLMå¢å¼ºçš„çŠ¶æ€è¡¨ç¤º**ï¼šè‡ªåŠ¨ç”Ÿæˆé¢†åŸŸç‰¹å®šçš„çŠ¶æ€ç‰¹å¾
- ğŸ **æ™ºèƒ½å¥–åŠ±è®¾è®¡**ï¼šLLMç”Ÿæˆå¹³è¡¡å¤šç›®æ ‡çš„å†…åœ¨å¥–åŠ±å‡½æ•°
- ğŸ† **å¤šç®—æ³•å¯¹æ¯”**ï¼šå†…ç½®Randomã€Myopicã€EIBç­‰åŸºå‡†ç®—æ³•
- ğŸ“Š **å®Œæ•´è¯„ä¼°ä½“ç³»**ï¼šæ”¯æŒå¤šç»´åº¦æ€§èƒ½åˆ†æå’Œå¯è§†åŒ–
- âš™ï¸ **çµæ´»é…ç½®**ï¼šYAMLé…ç½®æ–‡ä»¶ï¼Œæ”¯æŒå¿«é€Ÿå®éªŒè°ƒæ•´
- ğŸ”Œ **APIé›†æˆ**ï¼šæ”¯æŒChatAnywhereç­‰ç¬¬ä¸‰æ–¹LLM APIæœåŠ¡
- ğŸ“ˆ **å®æ—¶ç›‘æ§**ï¼šè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å’Œæ€§èƒ½è¿½è¸ª

### ğŸª åº”ç”¨åœºæ™¯

- ç”µå•†å¹³å°å•†å“æ¨èä¼˜åŒ–
- åº“å­˜ç®¡ç†ä¸é”€å”®ç­–ç•¥
- ä¸ªæ€§åŒ–è¥é”€ç­–ç•¥åˆ¶å®š
- ä¾›åº”é“¾ä¼˜åŒ–å†³ç­–

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.9+
- PyTorch 2.0+
- NumPy, Pandas, Matplotlib
- OpenAI API Key (æ¨èä½¿ç”¨ChatAnywhere)

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**
   ```bash
   git clone https://github.com/your-username/drl-assortment-lesr.git
   cd drl-assortment-lesr
   ```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**
   ```bash
   python -m venv .venv
   source .venv/bin/activate
   # Windows:
   .venv\Scripts\activate
   ```

3. **å®‰è£…ä¾èµ–**
   ```bash
   pip install -r requirements.txt
   ```

4. **é…ç½®APIå¯†é’¥**
   
   ç¼–è¾‘ `config/train_config.yaml`ï¼š
   ```yaml
   llm:
     api_key: "your-api-key-here"
     base_url: "https://api.chatanywhere.tech/v1"
     model: "gpt-4o-mini"
   ```

### è¿è¡Œç¤ºä¾‹

1. **æµ‹è¯•APIè¿æ¥**
   ```bash
   python api_test_script.py
   ```

2. **å¼€å§‹è®­ç»ƒ**
   ```bash
   python main.py --config config/train_config.yaml
   ```

3. **æŸ¥çœ‹ç»“æœ**
   ```bash
   # è®­ç»ƒå®Œæˆåï¼Œç»“æœä¿å­˜åœ¨ results/ ç›®å½•
   ls results/
   ```

## ğŸ“ é¡¹ç›®ç»“æ„

```
drl-assortment-lesr/
â”œâ”€â”€ ğŸ“ core/                    # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ llm_optimizer.py        # LLMä¼˜åŒ–å™¨
â”‚   â”œâ”€â”€ state_enhancer.py       # çŠ¶æ€å¢å¼ºå™¨
â”‚   â”œâ”€â”€ intrinsic_reward.py     # å†…åœ¨å¥–åŠ±è®¡ç®—å™¨
â”‚   â””â”€â”€ feedback_analyzer.py    # åé¦ˆåˆ†æå™¨
â”œâ”€â”€ ğŸ“ rl/                      # å¼ºåŒ–å­¦ä¹ æ¨¡å—
â”‚   â”œâ”€â”€ a2c_agent.py           # A2Cæ™ºèƒ½ä½“
â”‚   â”œâ”€â”€ environment.py         # ç¯å¢ƒå®šä¹‰
â”‚   â”œâ”€â”€ networks.py            # ç¥ç»ç½‘ç»œæ¶æ„
â”‚   â””â”€â”€ replay_buffer.py       # ç»éªŒå›æ”¾ç¼“å†²åŒº
â”œâ”€â”€ ğŸ“ baselines/               # åŸºå‡†ç®—æ³•
â”‚   â”œâ”€â”€ random_agent.py        # éšæœºç®—æ³•
â”‚   â”œâ”€â”€ myopic_agent.py        # è´ªå¿ƒç®—æ³•
â”‚   â””â”€â”€ eib_agent.py           # åº“å­˜å¹³è¡¡ç®—æ³•
â”œâ”€â”€ ğŸ“ utils/                   # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ evaluation.py          # è¯„ä¼°å·¥å…·
â”‚   â”œâ”€â”€ visualization.py       # å¯è§†åŒ–å·¥å…·
â”‚   â””â”€â”€ data_generator.py      # æ•°æ®ç”Ÿæˆå™¨
â”œâ”€â”€ ğŸ“ config/                  # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ train_config.yaml      # è®­ç»ƒé…ç½®
â”‚   â”œâ”€â”€ env_config.yaml        # ç¯å¢ƒé…ç½®
â”‚   â””â”€â”€ llm_prompts.yaml       # LLMæç¤ºæ¨¡æ¿
â”œâ”€â”€ ğŸ“„ main.py                 # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ ğŸ“„ requirements.txt        # ä¾èµ–åˆ—è¡¨
â””â”€â”€ ğŸ“„ README.md              # é¡¹ç›®æ–‡æ¡£
```

## âš™ï¸ é…ç½®è¯´æ˜

### è®­ç»ƒé…ç½® (`config/train_config.yaml`)

```yaml
# LLMé…ç½®
llm:
  model: "gpt-4o-mini"           # æ¨èä½¿ç”¨ä»·æ ¼ä¾¿å®œçš„æ¨¡å‹
  temperature: 0.7               # åˆ›é€ æ€§å‚æ•°
  samples_per_iteration: 3       # æ¯è½®è¿­ä»£çš„é‡‡æ ·æ•°
  max_iterations: 3              # æœ€å¤§è¿­ä»£æ¬¡æ•°

# ç¯å¢ƒé…ç½®
env:
  num_products: 10               # äº§å“æ•°é‡
  num_customer_types: 4          # å®¢æˆ·ç±»å‹æ•°
  cardinality: 4                 # æœ€å¤§å±•ç¤ºå•†å“æ•°
  
# è®­ç»ƒé…ç½®
training:
  episodes_per_sample: 200       # æ¯ä¸ªæ ·æœ¬çš„è®­ç»ƒè½®æ•°
  num_iterations: 3              # æ€»è¿­ä»£æ¬¡æ•°
```

### ç¯å¢ƒé…ç½® (`config/env_config.yaml`)

```yaml
environment:
  products:
    num_products: 10
    price_range: [1.0, 5.0]      # ä»·æ ¼èŒƒå›´
    
  customers:
    num_types: 4
    preference_type: "dirichlet"  # åå¥½åˆ†å¸ƒç±»å‹
    
  constraints:
    cardinality: 4                # å±•ç¤ºé™åˆ¶
    max_time: 100                 # æœ€å¤§æ—¶é—´æ­¥
```

## ğŸ® ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€è®­ç»ƒ

```python
import yaml
from core.llm_optimizer import LLMOptimizer
from rl.a2c_agent import A2CAgent
from rl.environment import AssortmentEnvironment

# åŠ è½½é…ç½®
with open('config/train_config.yaml', 'r') as f:
    config = yaml.safe_load(f)

# åˆå§‹åŒ–ç»„ä»¶
llm_optimizer = LLMOptimizer(
    api_key=config['llm']['api_key'],
    base_url=config['llm']['base_url'],
    model=config['llm']['model']
)

# ç”ŸæˆçŠ¶æ€è¡¨ç¤ºå‡½æ•°
state_func = llm_optimizer.generate_state_representation(
    task_description="ä¼˜åŒ–å•†å“æ¨èç­–ç•¥",
    state_info={'num_products': 10, 'customer_types': 4}
)

# å¼€å§‹è®­ç»ƒ...
```

### è‡ªå®šä¹‰çŠ¶æ€ç‰¹å¾

```python
# æ‰‹åŠ¨å®šä¹‰çŠ¶æ€å¢å¼ºå‡½æ•°
def custom_enhance_state(inventory, customer_type, prices, time_remaining, initial_inventory):
    # æ·»åŠ è‡ªå®šä¹‰ç‰¹å¾
    features = []
    
    # åŸºç¡€ç‰¹å¾
    relative_inventory = inventory / (initial_inventory + 1e-8)
    features.extend(relative_inventory)
    
    # è‡ªå®šä¹‰ç‰¹å¾
    urgency_score = calculate_urgency(inventory, time_remaining)
    features.append(urgency_score)
    
    return np.array(features)
```

### è¯„ä¼°å’Œå¯¹æ¯”

```python
from utils.evaluation import Evaluator

evaluator = Evaluator()

# å¯¹æ¯”å¤šä¸ªç®—æ³•
algorithms = {
    'DRL': trained_agent,
    'Random': RandomAgent(num_products=10, cardinality=4),
    'Myopic': MyopicAgent(num_products=10, cardinality=4)
}

results = evaluator.compare_algorithms(env, algorithms, num_episodes=100)
print(results)
```

## ğŸ“Š ç»“æœåˆ†æ

è®­ç»ƒå®Œæˆåï¼Œç³»ç»Ÿä¼šç”Ÿæˆä»¥ä¸‹è¾“å‡ºï¼š

### æ€§èƒ½æŒ‡æ ‡

- **æ€»æ”¶ç›Š (Total Revenue)**ï¼šé”€å”®æ€»æ”¶å…¥
- **å®¢æˆ·æ»¡æ„åº¦ (Customer Satisfaction)**ï¼šæˆåŠŸè´­ä¹°ç‡
- **åº“å­˜å¹³è¡¡åº¦ (Inventory Balance)**ï¼šåº“å­˜åˆ†å¸ƒå‡è¡¡æ€§
- **ç¼ºè´§ç‡ (Stockout Rate)**ï¼šç¼ºè´§å‘ç”Ÿé¢‘ç‡
- **åº“å­˜å‘¨è½¬ç‡ (Inventory Turnover)**ï¼šåº“å­˜ä½¿ç”¨æ•ˆç‡

### å¯è§†åŒ–æŠ¥å‘Š

```python
from utils.visualization import Visualizer

vis = Visualizer()

# ç»˜åˆ¶å­¦ä¹ æ›²çº¿
vis.plot_learning_curve(episode_rewards, save_path='results/learning_curve.png')

# ç»˜åˆ¶ç®—æ³•å¯¹æ¯”
vis.plot_comparison(comparison_df, save_path='results/algorithm_comparison.png')

# ç”Ÿæˆäº¤äº’å¼é¢æ¿
dashboard = vis.create_interactive_dashboard(results_data)
dashboard.show()
```

### ç¤ºä¾‹ç»“æœ

```
ğŸ“Š å®éªŒç»“æœæ‘˜è¦
==================================================
DRL-LESRæ€§èƒ½: 245.67 Â± 12.34
RandomåŸºå‡†: 180.23 Â± 15.67
MyopicåŸºå‡†: 210.45 Â± 11.89
EIBåŸºå‡†: 225.12 Â± 13.45

ç›¸å¯¹äºRandomæå‡: +36.3%
ç›¸å¯¹äºæœ€ä½³åŸºå‡†æå‡: +9.1%
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **APIè¿æ¥å¤±è´¥**
   ```bash
   # æµ‹è¯•APIè¿æ¥
   python api_test_script.py
   ```
   - æ£€æŸ¥API Keyæ˜¯å¦æ­£ç¡®
   - ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸
   - éªŒè¯base_urlæ ¼å¼

2. **å†…å­˜ä¸è¶³**
   ```yaml
   # å‡å°‘è®­ç»ƒå‚æ•°
   training:
     episodes_per_sample: 100  # ä»200å‡å°‘åˆ°100
     batch_size: 16           # ä»32å‡å°‘åˆ°16
   ```

3. **è®­ç»ƒå¤ªæ…¢**
   ```yaml
   # å‡å°‘è¿­ä»£æ¬¡æ•°
   llm:
     samples_per_iteration: 2  # ä»3å‡å°‘åˆ°2
     max_iterations: 2         # ä»3å‡å°‘åˆ°2
   ```

4. **CUDAç›¸å…³é”™è¯¯**
   ```bash
   # å¼ºåˆ¶ä½¿ç”¨CPU
   export CUDA_VISIBLE_DEVICES=""
   python main.py --config config/train_config.yaml
   ```

### è°ƒè¯•æ¨¡å¼

å¯ç”¨è¯¦ç»†æ—¥å¿—ï¼š

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿ç¤¾åŒºè´¡çŒ®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt

# è¿è¡Œæµ‹è¯•
python -m pytest tests/

# ä»£ç æ ¼å¼åŒ–
black .
flake8 .
```

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2024-01-XX)
- ğŸ‰ é¦–æ¬¡å‘å¸ƒ
- âœ¨ LLMå¢å¼ºçš„çŠ¶æ€è¡¨ç¤º
- ğŸš€ A2Cç®—æ³•å®ç°
- ğŸ“Š å®Œæ•´è¯„ä¼°ç³»ç»Ÿ

### è®¡åˆ’åŠŸèƒ½
- [ ] æ”¯æŒæ›´å¤šRLç®—æ³• (PPO, SAC)
- [ ] å¤šæ™ºèƒ½ä½“åä½œ
- [ ] åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
- [ ] Webç•Œé¢ç®¡ç†

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦æƒ…è¯·å‚è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ“ è”ç³»æ–¹å¼

- ä½œè€…ï¼šæ ¾å‰å®
- é‚®ç®±ï¼šluanjining@163.com
- é¡¹ç›®é“¾æ¥ï¼š[https://github.com/your-username/drl-assortment-lesr](https://github.com/LuanJining/drl-assortment-lesr)

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®å’ŒæŠ€æœ¯çš„æ”¯æŒï¼š

- [PyTorch](https://pytorch.org/) - æ·±åº¦å­¦ä¹ æ¡†æ¶
- [OpenAI](https://openai.com/) - GPT APIæœåŠ¡
- [ChatAnywhere](https://api.chatanywhere.tech/) - APIæœåŠ¡æä¾›å•†
- [Gymnasium](https://gymnasium.farama.org/) - å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ

---

â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª Starï¼

ğŸ’¡ æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Ÿæ¬¢è¿æäº¤ [Issue](https://github.com/your-username/drl-assortment-lesr/issues)ï¼
